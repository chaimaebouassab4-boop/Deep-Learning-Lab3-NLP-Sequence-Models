{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "137mvQyf9UT5rze80vUEs6LJ7oTb3RfDP",
      "authorship_tag": "ABX9TyPGoTjsYaSO9nOMcXU6Lu5U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3cf6086ce322451097bda038702bc072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a40b643dc371454597258c156c3b2be0",
              "IPY_MODEL_92397a9630104071bb385e2f299dacc3",
              "IPY_MODEL_a244a5d912444247b7da5ec4622012e8"
            ],
            "layout": "IPY_MODEL_564d0bf3f9644716b85e7d1673ab6f16"
          }
        },
        "a40b643dc371454597258c156c3b2be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb5eca1a428449dba7316d33a9a3d802",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b8cecd2e651449b49fea56d0f9ceae0d",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "92397a9630104071bb385e2f299dacc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4daab47e1cbe48f99c4a94a3fc4ed553",
            "max": 543432324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00cf8ada73f64068824d5860545e2edd",
            "value": 543432324
          }
        },
        "a244a5d912444247b7da5ec4622012e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d73f39add7541f7a38ae56fb1fa3d8f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_016283c266664eff84b8c344e8d2c0ee",
            "value": "â€‡543M/543Mâ€‡[00:06&lt;00:00,â€‡110MB/s]"
          }
        },
        "564d0bf3f9644716b85e7d1673ab6f16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb5eca1a428449dba7316d33a9a3d802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8cecd2e651449b49fea56d0f9ceae0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4daab47e1cbe48f99c4a94a3fc4ed553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00cf8ada73f64068824d5860545e2edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d73f39add7541f7a38ae56fb1fa3d8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "016283c266664eff84b8c344e8d2c0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaimaebouassab4-boop/Deep-Learning-Lab3-NLP-Sequence-Models/blob/main/lab3_dl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryRp9bibqpW6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#  main directories\n",
        "os.makedirs('data/raw', exist_ok=True)\n",
        "os.makedirs('data/processed', exist_ok=True)\n",
        "os.makedirs('models/gpt2_finetuned', exist_ok=True)\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "print(\"Directory structure created!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø©\n",
        "!pip install transformers datasets accelerate arabert farasapy torch scikit-learn nltk\n",
        "\n",
        "# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "DzLTBd1orFPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5ac0b2-c175-4b3a-df4c-0bf6e1dcdb24"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: arabert in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Requirement already satisfied: farasapy in /usr/local/lib/python3.12/dist-packages (0.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: PyArabic in /usr/local/lib/python3.12/dist-packages (from arabert) (0.6.15)\n",
            "Requirement already satisfied: emoji==1.4.2 in /usr/local/lib/python3.12/dist-packages (from arabert) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from PyArabic->arabert) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ØªÙ‚Ù†ÙŠØ© (Ù…ÙˆØ³Ø¹Ø© ÙˆØ­Ø¯ÙŠØ«Ø© 2025)\n",
        "texts = [\n",
        "    \"Ù‚Ø§Ù„Øª ÙˆÙƒØ§Ù„Ø© Ø§Ù„Ø£Ù†Ø¨Ø§Ø¡ Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ© Ø¥Ù† Ø´Ø±ÙƒØ© ØºÙˆØºÙ„ Ø£ØºÙ„Ù‚Øª Ø«ØºØ±ØªÙŠÙ† Ø£Ù…Ù†ÙŠØªÙŠÙ† ØªØ¤Ø«Ø±Ø§Ù† Ø¹Ù„Ù‰ Ù†Ø¸Ø§Ù… Ø£Ù†Ø¯Ø±ÙˆÙŠØ¯... ÙˆØªØ¹ØªÙ…Ø¯ Ø§Ù„Ø«ØºØ±Ø§Øª Ø¹Ù„Ù‰ Ø§Ø³ØªØºÙ„Ø§Ù„ Ø·Ø¨Ù‚Ø§Øª Ø¥Ø·Ø§Ø± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø£Ù†Ø¯Ø±ÙˆÙŠØ¯.\",\n",
        "    \"Ø­ÙØ¸ Ø¹Ù„Ù‰ Ø®Ù„Ø§Ù Ù†Ø¨ÙˆØ¡Ø§Øª Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ÙˆØ¸Ø§Ø¦ÙØŒ ÙŠÙƒØ´Ù ØªÙ‚Ø±ÙŠØ± Ù„ØµØ­ÙŠÙØ© Ø¥ÙŠÙƒÙˆÙ†ÙˆÙ…ÙŠØ³Øª Ø£Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ø§ ÙŠÙƒØªÙÙŠ Ø¨Ø¹Ø¯Ù… Ø§Ù„Ù‚Ø¶Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù…Ù„ØŒ Ø¨Ù„ ÙŠØ®Ù„Ù‚ ÙØ¦Ø§Øª ÙˆØ¸ÙŠÙÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©... ÙˆØ£Ù† Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø¨Ø´Ø±ÙŠØ© Ø£ØµØ¨Ø­Øª Ø§Ù„Ø¹Ù…Ù„Ø© Ø§Ù„Ø£Ø¹Ù„Ù‰ Ù‚ÙŠÙ…Ø© ÙÙŠ Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯.\",\n",
        "    \"ÙˆÙˆÙÙ‚Ø§ Ù„ØªÙ‚Ø±ÙŠØ± Ù†Ø´Ø±Ù‡ Ù…ÙˆÙ‚Ø¹ Ø¨ÙŠ Ø¢Ø± Ù†ÙŠÙˆØ² ÙˆØ§ÙŠØ±ØŒ Ù…Ù† Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ø£Ù† ÙŠØµÙ„ Ø³ÙˆÙ‚ ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ø¨Ù„ÙˆÙƒ ØªØ´ÙŠÙ† Ø¥Ù„Ù‰ 39.7 Ù…Ù„ÙŠØ§Ø± Ø¯ÙˆÙ„Ø§Ø± Ø¨Ø­Ù„ÙˆÙ„ Ø¹Ø§Ù… 2025...\",\n",
        "    \"Ø§Ø®ØªØ§Ø±Øª Ù…Ø¬Ù„Ø© ØªØ§ÙŠÙ… Ø§Ù„Ø£Ù…ÙŠØ±ÙƒÙŠØ© Ù…Ù‡Ù†Ø¯Ø³ÙŠ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø´Ø®ØµÙŠØ© Ø¹Ø§Ù… 2025ØŒ ÙˆÙÙŠ Ù…Ù‚Ø¯Ù…ØªÙ‡Ù… Ø¬Ù†Ø³Ù† Ù‡ÙˆØ§Ù†ØºØŒ Ø§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ Ù„Ø´Ø±ÙƒØ© Ø¥Ù†ÙÙŠØ¯ÙŠØ§.\",\n",
        "    \"Ø£Ø·Ù„Ù‚Øª Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© ØªØ·Ø¨ÙŠÙ‚ HUMAIN ChatØŒ Ø£ÙˆÙ„ ØªØ·Ø¨ÙŠÙ‚ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø­ÙˆØ§Ø±ÙŠ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ù…Ø¯Ø¹ÙˆÙ…Ø§Ù‹ Ø¨Ù†Ù…ÙˆØ°Ø¬ ALLaM 34B.\",\n",
        "    \"Ø£Ø¹Ù„Ù†Øª Ø£Ø¨ÙˆØ¸Ø¨ÙŠ ÙˆØ´Ø±ÙƒØ© Nvidia Ø¹Ù† Ø¥Ø·Ù„Ø§Ù‚ Ù…Ø®ØªØ¨Ø± Ù…Ø´ØªØ±Ùƒ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„Ø±ÙˆØ¨ÙˆØªØ§Øª.\",\n",
        "    \"ØªÙˆÙ‚Ø¹Ø§Øª 2025: Ø³ÙŠØ·Ø± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„ØªÙ‡Ø¯ÙŠØ¯Ø§Øª Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø© Deepfakes Ø¹Ù„Ù‰ Ù†Ù‚Ø§Ø´Ø§Øª Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ.\",\n",
        "    \"ÙÙŠ Ø¹Ø§Ù… 2025ØŒ ÙŠØ¹ÙŠØ¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„Ø­ÙˆØ³Ø¨Ø© Ø§Ù„ÙƒÙ…ÙˆÙ…ÙŠØ© ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ.\",\n",
        "    \"Ø£Ø¹Ù„Ù†Øª Ø¨Ø§Ù„Ùˆ Ø£Ù„ØªÙˆ Ù†ØªÙˆØ±ÙƒØ³ Ø£Ù† 2025 Ø¹Ø§Ù… Ø§Ù„Ø§Ø¶Ø·Ø±Ø§Ø¨ Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠØŒ Ù…Ø¹ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù‡Ø¬Ù…Ø§Øª ÙˆØ§Ø³Ø¹Ø© Ø§Ù„Ù†Ø·Ø§Ù‚.\",\n",
        "    \"ÙƒØ´ÙØª ØªÙ‚Ø§Ø±ÙŠØ± Ø¹Ù† Ù‡Ø¬Ù…Ø§Øª ÙÙŠØ´ÙŠÙ†Øº ØªØ¬Ø§ÙˆØ²Øª 6.3 Ù…Ù„ÙŠÙˆÙ† Ù…Ø­Ø§ÙˆÙ„Ø© ÙÙŠ 2025 Ø¹Ù„Ù‰ Ù…Ù†ØµØ§Øª Ø§Ù„ØªØ³ÙˆÙ‚ ÙˆØ§Ù„Ø£Ù„Ø¹Ø§Ø¨.\"\n",
        "]\n",
        "\n",
        "scores = [9.5, 9.2, 8.0, 9.8, 9.7, 9.4, 9.0, 8.8, 9.1, 8.5]\n",
        "\n",
        "df = pd.DataFrame({'Text': texts, 'Score': scores})\n",
        "\n",
        "# Ø­ÙØ¸ ÙÙŠ Colab (Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ø§Ù„Ø¢Ù†)\n",
        "df.to_csv('/content/arabic_tech_dataset.csv', index=False)\n",
        "\n",
        "print(df)\n",
        "print(\"\\nØªÙ… Ø­ÙØ¸ Ø§Ù„Ù€ Dataset ÙÙŠ /content/arabic_tech_dataset.csv\")"
      ],
      "metadata": {
        "id": "gKUeBe47rKw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d81ce74-1547-48b6-ec43-a7a9961e3ab3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text  Score\n",
            "0  Ù‚Ø§Ù„Øª ÙˆÙƒØ§Ù„Ø© Ø§Ù„Ø£Ù†Ø¨Ø§Ø¡ Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ© Ø¥Ù† Ø´Ø±ÙƒØ© ØºÙˆØºÙ„ Ø£ØºÙ„Ù‚...    9.5\n",
            "1  Ø­ÙØ¸ Ø¹Ù„Ù‰ Ø®Ù„Ø§Ù Ù†Ø¨ÙˆØ¡Ø§Øª Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ÙˆØ¸Ø§Ø¦ÙØŒ ÙŠÙƒØ´Ù ØªÙ‚Ø±ÙŠØ± ...    9.2\n",
            "2  ÙˆÙˆÙÙ‚Ø§ Ù„ØªÙ‚Ø±ÙŠØ± Ù†Ø´Ø±Ù‡ Ù…ÙˆÙ‚Ø¹ Ø¨ÙŠ Ø¢Ø± Ù†ÙŠÙˆØ² ÙˆØ§ÙŠØ±ØŒ Ù…Ù† Ø§Ù„Ù…...    8.0\n",
            "3  Ø§Ø®ØªØ§Ø±Øª Ù…Ø¬Ù„Ø© ØªØ§ÙŠÙ… Ø§Ù„Ø£Ù…ÙŠØ±ÙƒÙŠØ© Ù…Ù‡Ù†Ø¯Ø³ÙŠ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·...    9.8\n",
            "4  Ø£Ø·Ù„Ù‚Øª Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© ØªØ·Ø¨ÙŠÙ‚ HUMAIN ChatØŒ Ø£ÙˆÙ„ ØªØ·Ø¨ÙŠÙ‚ Ø°Ùƒ...    9.7\n",
            "5  Ø£Ø¹Ù„Ù†Øª Ø£Ø¨ÙˆØ¸Ø¨ÙŠ ÙˆØ´Ø±ÙƒØ© Nvidia Ø¹Ù† Ø¥Ø·Ù„Ø§Ù‚ Ù…Ø®ØªØ¨Ø± Ù…Ø´ØªØ±Ùƒ...    9.4\n",
            "6  ØªÙˆÙ‚Ø¹Ø§Øª 2025: Ø³ÙŠØ·Ø± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„ØªÙ‡Ø¯ÙŠØ¯Ø§Øª ...    9.0\n",
            "7  ÙÙŠ Ø¹Ø§Ù… 2025ØŒ ÙŠØ¹ÙŠØ¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„Ø­ÙˆØ³Ø¨Ø© Ø§Ù„...    8.8\n",
            "8  Ø£Ø¹Ù„Ù†Øª Ø¨Ø§Ù„Ùˆ Ø£Ù„ØªÙˆ Ù†ØªÙˆØ±ÙƒØ³ Ø£Ù† 2025 Ø¹Ø§Ù… Ø§Ù„Ø§Ø¶Ø·Ø±Ø§Ø¨ Ø§Ù„...    9.1\n",
            "9  ÙƒØ´ÙØª ØªÙ‚Ø§Ø±ÙŠØ± Ø¹Ù† Ù‡Ø¬Ù…Ø§Øª ÙÙŠØ´ÙŠÙ†Øº ØªØ¬Ø§ÙˆØ²Øª 6.3 Ù…Ù„ÙŠÙˆÙ† Ù…...    8.5\n",
            "\n",
            "ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù€ Dataset ÙÙŠ /content/arabic_tech_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"aubmindlab/bert-base-arabertv2\"\n",
        "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
        "\n",
        "def arabic_preprocess(text):\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = arabert_prep.preprocess(text)\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['Text'].apply(arabic_preprocess)\n",
        "df.to_csv('/content/arabic_tech_preprocessed.csv', index=False)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "print(\"ØªÙ… Ø§Ù„Ù€ Preprocessing Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "print(df[['Text', 'clean_text', 'Score']].head())"
      ],
      "metadata": {
        "id": "0Y9DKieHqz3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08cd355c-0d77-4087-d81d-26fad26a1f56"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-12-18 23:17:01,746 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ØªÙ… Ø§Ù„Ù€ Preprocessing Ø¨Ù†Ø¬Ø§Ø­!\n",
            "                                                Text  \\\n",
            "0  Ù‚Ø§Ù„Øª ÙˆÙƒØ§Ù„Ø© Ø§Ù„Ø£Ù†Ø¨Ø§Ø¡ Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ© Ø¥Ù† Ø´Ø±ÙƒØ© ØºÙˆØºÙ„ Ø£ØºÙ„Ù‚...   \n",
            "1  Ø­ÙØ¸ Ø¹Ù„Ù‰ Ø®Ù„Ø§Ù Ù†Ø¨ÙˆØ¡Ø§Øª Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ÙˆØ¸Ø§Ø¦ÙØŒ ÙŠÙƒØ´Ù ØªÙ‚Ø±ÙŠØ± ...   \n",
            "2  ÙˆÙˆÙÙ‚Ø§ Ù„ØªÙ‚Ø±ÙŠØ± Ù†Ø´Ø±Ù‡ Ù…ÙˆÙ‚Ø¹ Ø¨ÙŠ Ø¢Ø± Ù†ÙŠÙˆØ² ÙˆØ§ÙŠØ±ØŒ Ù…Ù† Ø§Ù„Ù…...   \n",
            "3  Ø§Ø®ØªØ§Ø±Øª Ù…Ø¬Ù„Ø© ØªØ§ÙŠÙ… Ø§Ù„Ø£Ù…ÙŠØ±ÙƒÙŠØ© Ù…Ù‡Ù†Ø¯Ø³ÙŠ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·...   \n",
            "4  Ø£Ø·Ù„Ù‚Øª Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© ØªØ·Ø¨ÙŠÙ‚ HUMAIN ChatØŒ Ø£ÙˆÙ„ ØªØ·Ø¨ÙŠÙ‚ Ø°Ùƒ...   \n",
            "\n",
            "                                          clean_text  Score  \n",
            "0  Ù‚Ø§Ù„ +Øª ÙˆÙƒØ§Ù„ +Ø© Ø§Ù„+ Ø£Ù†Ø¨Ø§Ø¡ Ø§Ù„+ Ø£Ù„Ù…Ø§Ù†ÙŠ +Ø© Ø¥Ù† Ø´Ø±Ùƒ ...    9.5  \n",
            "1  Ø­ÙØ¸ Ø¹Ù„Ù‰ Ø®Ù„Ø§Ù Ù†Ø¨ÙˆØ¡ +Ø§Øª Ù†Ù‡Ø§ÙŠ +Ø© Ø§Ù„+ ÙˆØ¸Ø§Ø¦Ù ÙŠÙƒØ´Ù Øª...    9.2  \n",
            "2  Ùˆ+ ÙˆÙÙ‚ +Ø§ Ù„+ ØªÙ‚Ø±ÙŠØ± Ù†Ø´Ø± +Ù‡ Ù…ÙˆÙ‚Ø¹ Ø¨ÙŠ Ø¢Ø± Ù†ÙŠÙˆØ² Ùˆ+ Ø§...    8.0  \n",
            "3  Ø§Ø®ØªØ§Ø± +Øª Ù…Ø¬Ù„ +Ø© ØªØ§ÙŠÙ… Ø§Ù„+ Ø£Ù…ÙŠØ±ÙƒÙŠ +Ø© Ù…Ù‡Ù†Ø¯Ø³ +ÙŠ Ø§Ù„...    9.8  \n",
            "4  Ø£Ø·Ù„Ù‚ +Øª Ø§Ù„+ Ø³Ø¹ÙˆØ¯ÙŠ +Ø© ØªØ·Ø¨ÙŠÙ‚ HUMAIN Chat Ø£ÙˆÙ„ ØªØ·Ø¨...    9.7  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "arabert_model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_texts(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "texts_clean = df['clean_text'].tolist()\n",
        "scores = df['Score'].values\n",
        "\n",
        "encodings = tokenize_texts(texts_clean)\n",
        "\n",
        "class TechDataset(Dataset):\n",
        "    def __init__(self, encodings, scores):\n",
        "        self.encodings = encodings\n",
        "        self.scores = torch.tensor(scores, dtype=torch.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.scores[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.scores)\n",
        "\n",
        "train_texts, val_texts, train_scores, val_scores = train_test_split(texts_clean, scores, test_size=0.25, random_state=42)\n",
        "\n",
        "train_enc = tokenize_texts(train_texts)\n",
        "val_enc = tokenize_texts(val_texts)\n",
        "\n",
        "train_dataset = TechDataset(train_enc, train_scores)\n",
        "val_dataset = TechDataset(val_enc, val_scores)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4)"
      ],
      "metadata": {
        "id": "2DlV06eUuB8Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3cf6086ce322451097bda038702bc072",
            "a40b643dc371454597258c156c3b2be0",
            "92397a9630104071bb385e2f299dacc3",
            "a244a5d912444247b7da5ec4622012e8",
            "564d0bf3f9644716b85e7d1673ab6f16",
            "eb5eca1a428449dba7316d33a9a3d802",
            "b8cecd2e651449b49fea56d0f9ceae0d",
            "4daab47e1cbe48f99c4a94a3fc4ed553",
            "00cf8ada73f64068824d5860545e2edd",
            "9d73f39add7541f7a38ae56fb1fa3d8f",
            "016283c266664eff84b8c344e8d2c0ee"
          ]
        },
        "outputId": "0f2e1c01-2cfb-47cb-aec8-0101d11a65b3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cf6086ce322451097bda038702bc072"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceRegressor(nn.Module):\n",
        "    def __init__(self, seq_type='lstm', hidden_size=256, num_layers=2, bidirectional=False, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.embedding = arabert_model.embeddings\n",
        "        self.seq_type = seq_type\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        if seq_type == 'rnn':\n",
        "            self.rnn = nn.RNN(768, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional, dropout=dropout)\n",
        "        elif seq_type == 'gru':\n",
        "            self.rnn = nn.GRU(768, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional, dropout=dropout)\n",
        "        elif seq_type == 'lstm':\n",
        "            self.rnn = nn.LSTM(768, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional, dropout=dropout)\n",
        "\n",
        "        mult = 2 if bidirectional else 1\n",
        "        self.fc = nn.Linear(hidden_size * mult, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        with torch.no_grad():\n",
        "            emb = self.embedding(input_ids)\n",
        "\n",
        "        mask = attention_mask.unsqueeze(-1).expand(emb.size()).float()\n",
        "        emb = emb * mask\n",
        "\n",
        "        out, _ = self.rnn(emb)\n",
        "        out = out[:, -1, :]  # Ø¢Ø®Ø± Ø­Ø§Ù„Ø© Ù…Ø®ÙÙŠØ©\n",
        "        out = self.dropout(out)\n",
        "        return self.fc(out).squeeze()\n",
        "\n",
        "def train_and_evaluate(model_name, seq_type, bidirectional):\n",
        "    model = SequenceRegressor(seq_type=seq_type, hidden_size=256, num_layers=2, bidirectional=bidirectional)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(30):\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
        "            loss = loss_fn(preds, batch['labels'].to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # ØªÙ‚ÙŠÙŠÙ…\n",
        "    model.eval()\n",
        "    preds, true = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            p = model(batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
        "            preds.extend(p.cpu().numpy())\n",
        "            true.extend(batch['labels'].numpy())\n",
        "\n",
        "    mae = mean_absolute_error(true, preds)\n",
        "    rmse = np.sqrt(mean_squared_error(true, preds))\n",
        "    r2 = r2_score(true, preds)\n",
        "\n",
        "    # BLEU Ø¨Ø¹Ø¯ discretization\n",
        "    def score_to_cat(s):\n",
        "        if s >= 9: return \"Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹\"\n",
        "        elif s >= 8: return \"Ø¹Ø§Ù„ÙŠØ©\"\n",
        "        elif s >= 7: return \"Ø¬ÙŠØ¯Ø©\"\n",
        "        else: return \"Ù…Ù†Ø®ÙØ¶Ø©\"\n",
        "\n",
        "    pred_cat = [score_to_cat(p) for p in preds]\n",
        "    true_cat = [score_to_cat(t) for t in true]\n",
        "\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    bleu = np.mean([sentence_bleu([ref.split()], hyp.split(), smoothing_function=smoothie) for ref, hyp in zip(true_cat, pred_cat)])\n",
        "\n",
        "    print(f\"{model_name} | MAE: {mae:.3f} | RMSE: {rmse:.3f} | RÂ²: {r2:.3f} | BLEU: {bleu:.3f}\")\n",
        "\n",
        "    return mae\n",
        "\n",
        "# ØªØ¯Ø±ÙŠØ¨ ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø±Ø¨Ø¹Ø©\n",
        "print(\"=== Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ===\")\n",
        "train_and_evaluate(\"RNN\", 'rnn', False)\n",
        "train_and_evaluate(\"Bi-RNN\", 'rnn', True)\n",
        "train_and_evaluate(\"Bi-GRU\", 'gru', True)\n",
        "train_and_evaluate(\"Bi-LSTM\", 'lstm', True)"
      ],
      "metadata": {
        "id": "WZzAX6ENuDlZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7d8bc5-4b06-4492-90b2-1a472168a1a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ===\n",
            "RNN | MAE: 0.110 | RMSE: 0.149 | RÂ²: -0.419 | BLEU: 0.221\n",
            "Bi-RNN | MAE: 0.224 | RMSE: 0.259 | RÂ²: -3.302 | BLEU: 0.319\n",
            "Bi-GRU | MAE: 0.410 | RMSE: 0.470 | RÂ²: -13.197 | BLEU: 0.319\n",
            "Bi-LSTM | MAE: 0.254 | RMSE: 0.287 | RÂ²: -4.298 | BLEU: 0.319\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2536328633626302"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x38S1npkwt42",
        "outputId": "05b183f8-faf4-4add-b7fa-2eb7496ee655"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù†ØµÙˆØµ ÙÙŠ Ù…Ù„Ù Ù„Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "full_text = \"\\n\\n\".join(df['Text'].tolist())\n",
        "\n",
        "with open('/content/tech_corpus.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(full_text)\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ AraGPT2\n",
        "gpt_model_name = \"aubmindlab/aragpt2-base\"\n",
        "tokenizer_gpt = GPT2Tokenizer.from_pretrained(gpt_model_name)\n",
        "tokenizer_gpt.pad_token = tokenizer_gpt.eos_token\n",
        "\n",
        "model_gpt = GPT2LMHeadModel.from_pretrained(gpt_model_name)\n",
        "\n",
        "# Ø¥Ø¹Ø¯Ø§Ø¯ Dataset\n",
        "train_dataset = TextDataset(tokenizer=tokenizer_gpt, file_path=\"/content/tech_corpus.txt\", block_size=128)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer_gpt, mlm=False)\n",
        "\n",
        "# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/aragpt2-finetuned\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=5e-5,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model_gpt,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        ")\n",
        "\n",
        "print(\"Ø¨Ø¯Ø¡ Fine-tuning...\")\n",
        "trainer.train()\n",
        "\n",
        "# Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
        "model_gpt.save_pretrained(\"/content/aragpt2-finetuned\")\n",
        "tokenizer_gpt.save_pretrained(\"/content/aragpt2-finetuned\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R95Ad6b5tJXS",
        "outputId": "ed9f6090-2d20-4ace-dd87-f6b995141ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ø¨Ø¯Ø¡ Fine-tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_gen = GPT2LMHeadModel.from_pretrained(\"/content/aragpt2-finetuned\")\n",
        "tokenizer_gen = GPT2Tokenizer.from_pretrained(\"/content/aragpt2-finetuned\")\n",
        "tokenizer_gen.pad_token = tokenizer_gen.eos_token\n",
        "\n",
        "def generate_text(prompt, max_length=300):\n",
        "    prompt_clean = arabert_prep.preprocess(prompt)\n",
        "    inputs = tokenizer_gen(prompt_clean, return_tensors=\"pt\")\n",
        "\n",
        "    outputs = model_gen.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        num_beams=5,\n",
        "        temperature=0.8,\n",
        "        no_repeat_ngram_size=3,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    text = tokenizer_gen.decode(outputs[0], skip_special_tokens=True)\n",
        "    text = arabert_prep.unpreprocess(text)\n",
        "    return text\n",
        "\n",
        "# Ø§Ø®ØªØ¨Ø§Ø±\n",
        "prompt = \"ÙÙŠ Ø¹Ø§Ù… 2026ØŒ Ù…Ù† Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ø£Ù† ÙŠØµØ¨Ø­ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ\"\n",
        "print(generate_text(prompt))"
      ],
      "metadata": {
        "id": "077FKbcttxYw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}